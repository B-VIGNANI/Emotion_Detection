{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c192100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Importing required libraries\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "import tempfile\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import ImageTk, Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd73e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Feature extraction and dataset loading\n",
    "def extract_features(file_path):\n",
    "    audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    features = np.mean(librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13).T, axis=0)\n",
    "    return features\n",
    "\n",
    "dataset_path = r\"C:\\Users\\moham\\Downloads\\Emotion_Recognition_Project\\Speech_Emotion_Recognition\\TESS Toronto emotional speech set data\"\n",
    "\n",
    "data, labels = [], []\n",
    "for folder_name in os.listdir(dataset_path):\n",
    "    folder_path = os.path.join(dataset_path, folder_name)\n",
    "    for file_path in glob.glob(os.path.join(folder_path, '*.wav')):\n",
    "        features = extract_features(file_path)\n",
    "        data.append(features)\n",
    "        labels.append(folder_name)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)[:, np.newaxis, :]\n",
    "X_test = np.array(X_test)[:, np.newaxis, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09ab606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.0641 - loss: 2.8460 - val_accuracy: 0.0768 - val_loss: 2.6476\n",
      "Epoch 2/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0660 - loss: 2.6992 - val_accuracy: 0.1286 - val_loss: 2.6201\n",
      "Epoch 3/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0710 - loss: 2.6723 - val_accuracy: 0.0679 - val_loss: 2.6147\n",
      "Epoch 4/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0859 - loss: 2.6444 - val_accuracy: 0.1750 - val_loss: 2.5936\n",
      "Epoch 5/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0875 - loss: 2.6388 - val_accuracy: 0.2143 - val_loss: 2.5509\n",
      "Epoch 6/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1033 - loss: 2.6020 - val_accuracy: 0.2607 - val_loss: 2.4687\n",
      "Epoch 7/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1192 - loss: 2.5454 - val_accuracy: 0.2446 - val_loss: 2.3857\n",
      "Epoch 8/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1484 - loss: 2.4610 - val_accuracy: 0.2929 - val_loss: 2.2147\n",
      "Epoch 9/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.1890 - loss: 2.3287 - val_accuracy: 0.2964 - val_loss: 2.0959\n",
      "Epoch 10/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2243 - loss: 2.1880 - val_accuracy: 0.3643 - val_loss: 1.9754\n",
      "Epoch 11/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2743 - loss: 2.0676 - val_accuracy: 0.4786 - val_loss: 1.7867\n",
      "Epoch 12/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.2993 - loss: 1.9434 - val_accuracy: 0.4964 - val_loss: 1.6757\n",
      "Epoch 13/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3449 - loss: 1.8066 - val_accuracy: 0.5304 - val_loss: 1.5061\n",
      "Epoch 14/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3914 - loss: 1.6859 - val_accuracy: 0.5339 - val_loss: 1.3927\n",
      "Epoch 15/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4068 - loss: 1.5748 - val_accuracy: 0.6232 - val_loss: 1.2714\n",
      "Epoch 16/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4731 - loss: 1.4476 - val_accuracy: 0.6464 - val_loss: 1.1606\n",
      "Epoch 17/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5132 - loss: 1.3369 - val_accuracy: 0.7054 - val_loss: 1.0562\n",
      "Epoch 18/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5317 - loss: 1.2437 - val_accuracy: 0.7321 - val_loss: 0.9510\n",
      "Epoch 19/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6111 - loss: 1.1151 - val_accuracy: 0.7714 - val_loss: 0.8249\n",
      "Epoch 20/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6343 - loss: 1.0259 - val_accuracy: 0.8339 - val_loss: 0.7253\n",
      "Epoch 21/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6436 - loss: 0.9946 - val_accuracy: 0.8214 - val_loss: 0.6459\n",
      "Epoch 22/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6938 - loss: 0.8631 - val_accuracy: 0.8393 - val_loss: 0.5465\n",
      "Epoch 23/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7302 - loss: 0.7916 - val_accuracy: 0.8893 - val_loss: 0.4583\n",
      "Epoch 24/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7482 - loss: 0.7152 - val_accuracy: 0.8821 - val_loss: 0.4200\n",
      "Epoch 25/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7731 - loss: 0.6733 - val_accuracy: 0.8875 - val_loss: 0.3837\n",
      "Epoch 26/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7917 - loss: 0.6212 - val_accuracy: 0.8946 - val_loss: 0.3815\n",
      "Epoch 27/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7837 - loss: 0.6405 - val_accuracy: 0.9036 - val_loss: 0.3175\n",
      "Epoch 28/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7725 - loss: 0.6111 - val_accuracy: 0.8911 - val_loss: 0.3304\n",
      "Epoch 29/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8078 - loss: 0.5500 - val_accuracy: 0.9018 - val_loss: 0.3230\n",
      "Epoch 30/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8147 - loss: 0.5431 - val_accuracy: 0.8946 - val_loss: 0.2940\n",
      "Epoch 31/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8441 - loss: 0.4764 - val_accuracy: 0.9054 - val_loss: 0.2943\n",
      "Epoch 32/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8416 - loss: 0.4641 - val_accuracy: 0.9196 - val_loss: 0.2549\n",
      "Epoch 33/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8352 - loss: 0.4713 - val_accuracy: 0.9071 - val_loss: 0.2661\n",
      "Epoch 34/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8501 - loss: 0.4290 - val_accuracy: 0.9125 - val_loss: 0.2458\n",
      "Epoch 35/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8565 - loss: 0.4226 - val_accuracy: 0.9196 - val_loss: 0.2495\n",
      "Epoch 36/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8544 - loss: 0.4404 - val_accuracy: 0.9196 - val_loss: 0.2361\n",
      "Epoch 37/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8445 - loss: 0.4447 - val_accuracy: 0.9125 - val_loss: 0.2371\n",
      "Epoch 38/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8385 - loss: 0.4429 - val_accuracy: 0.9196 - val_loss: 0.2272\n",
      "Epoch 39/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8550 - loss: 0.3973 - val_accuracy: 0.9071 - val_loss: 0.2489\n",
      "Epoch 40/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8733 - loss: 0.3974 - val_accuracy: 0.9214 - val_loss: 0.2371\n",
      "Epoch 41/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8396 - loss: 0.4541 - val_accuracy: 0.9268 - val_loss: 0.2182\n",
      "Epoch 42/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8510 - loss: 0.4241 - val_accuracy: 0.9304 - val_loss: 0.2132\n",
      "Epoch 43/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8680 - loss: 0.3753 - val_accuracy: 0.9214 - val_loss: 0.2243\n",
      "Epoch 44/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8557 - loss: 0.3917 - val_accuracy: 0.9250 - val_loss: 0.2111\n",
      "Epoch 45/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8736 - loss: 0.3640 - val_accuracy: 0.8964 - val_loss: 0.2558\n",
      "Epoch 46/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8539 - loss: 0.3953 - val_accuracy: 0.9214 - val_loss: 0.2169\n",
      "Epoch 47/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8762 - loss: 0.3609 - val_accuracy: 0.9268 - val_loss: 0.2166\n",
      "Epoch 48/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8568 - loss: 0.3925 - val_accuracy: 0.9143 - val_loss: 0.2061\n",
      "Epoch 49/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8691 - loss: 0.3379 - val_accuracy: 0.9071 - val_loss: 0.2301\n",
      "Epoch 50/50\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8637 - loss: 0.3754 - val_accuracy: 0.9268 - val_loss: 0.2315\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2640\n",
      "Test loss: 0.23150697350502014\n",
      "Test accuracy: 0.9267857074737549\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Build and train the LSTM model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Dense(256, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64286eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Prediction logic\n",
    "def predict_emotion(audio_file):\n",
    "    features = extract_features(audio_file)\n",
    "    features = features[np.newaxis, np.newaxis, :]\n",
    "    predicted_probabilities = model.predict(features)[0]\n",
    "    predicted_index = np.argmax(predicted_probabilities)\n",
    "    predicted_label = label_encoder.classes_[predicted_index]\n",
    "    \n",
    "    emotion_mapping = {\n",
    "        'YAF_angry': 'ANGRY', 'YAF_disgust': 'DISGUST', 'YAF_fear': 'FEAR',\n",
    "        'YAF_happy': 'HAPPY', 'YAF_neutral': 'NEUTRAL', 'YAF_pleasant_surprised': 'SURPRISED', 'YAF_sad': 'SAD',\n",
    "        'OAF_angry': 'ANGRY', 'OAF_disgust': 'DISGUST', 'OAF_Fear': 'FEAR',\n",
    "        'OAF_happy': 'HAPPY', 'OAF_neutral': 'NEUTRAL', 'OAF_Pleasant_surprised': 'SURPRISED', 'OAF_Sad': 'SAD',\n",
    "    }\n",
    "    \n",
    "    readable_emotion = emotion_mapping.get(predicted_label, \"UNKNOWN\")\n",
    "    emotion_labels = ['HAPPY', 'SAD', 'ANGRY', 'SURPRISED', 'NEUTRAL', 'FEAR', 'DISGUST']\n",
    "    probabilities = dict(zip(emotion_labels, [0]*len(emotion_labels)))\n",
    "    if readable_emotion in probabilities:\n",
    "        probabilities[readable_emotion] = 1.0  # set detected emotion prob to 1.0\n",
    "\n",
    "    return readable_emotion, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d526742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: GUI class definition\n",
    "class EmotionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Speech Emotion Recognition\")\n",
    "        self.root.geometry(\"1000x600\")\n",
    "        self.dark_mode = False\n",
    "\n",
    "        self.base_emoji_path = r\"C:\\\\Users\\\\moham\\\\Downloads\\\\Emotion_Recognition_Project\\\\Speech_Emotion_Recognition\\\\Emotion Emojis\\\\Emoji\"\n",
    "        self.logo_path = r\"C:\\\\Users\\\\moham\\\\Downloads\\\\Emotion_Recognition_Project\\\\Speech_Emotion_Recognition\\\\images\\\\logo.png\"\n",
    "        self.emotion_to_emoji = {\n",
    "            \"HAPPY\": os.path.join(self.base_emoji_path, \"happy.gif\"),\n",
    "            \"SAD\": os.path.join(self.base_emoji_path, \"sad.gif\"),\n",
    "            \"ANGRY\": os.path.join(self.base_emoji_path, \"angry.gif\"),\n",
    "            \"SURPRISED\": os.path.join(self.base_emoji_path, \"surprised.gif\"),\n",
    "            \"NEUTRAL\": os.path.join(self.base_emoji_path, \"neutral.gif\"),\n",
    "            \"FEAR\": os.path.join(self.base_emoji_path, \"fear.gif\"),\n",
    "            \"DISGUST\": os.path.join(self.base_emoji_path, \"disgust.gif\")\n",
    "        }\n",
    "\n",
    "        self.emoji_label = None\n",
    "        self.emoji_image = None\n",
    "        self.prediction_history = []\n",
    "        self.create_menu()\n",
    "        self.show_home_page()\n",
    "\n",
    "    def create_menu(self):\n",
    "        self.menubar = tk.Menu(self.root)\n",
    "        app_menu = tk.Menu(self.menubar, tearoff=0)\n",
    "        app_menu.add_command(label=\"User Manual\", command=self.show_user_manual)\n",
    "        app_menu.add_command(label=\"Toggle Dark Mode\", command=self.toggle_dark_mode)\n",
    "        app_menu.add_command(label=\"About the App\", command=self.show_about_page)\n",
    "        self.menubar.add_cascade(label=\"Menu\", menu=app_menu)\n",
    "        self.root.config(menu=self.menubar)\n",
    "\n",
    "    def clear_window(self):\n",
    "        for widget in self.root.winfo_children():\n",
    "            if not isinstance(widget, tk.Menu):\n",
    "                widget.destroy()\n",
    "\n",
    "    def apply_theme(self):\n",
    "        bg = '#1e1e1e' if self.dark_mode else 'white'\n",
    "        fg = 'white' if self.dark_mode else 'black'\n",
    "        self.root.configure(bg=bg)\n",
    "        return bg, fg\n",
    "\n",
    "    def back_button(self, command):\n",
    "        tk.Button(self.root, text=\"\\u2190 Back\", command=command, bg='lightgrey').place(x=10, y=10)\n",
    "\n",
    "    def show_home_page(self):\n",
    "        self.clear_window()\n",
    "        bg, fg = self.apply_theme()\n",
    "        left_frame = tk.Frame(self.root, bg=bg)\n",
    "        left_frame.pack(side='left', fill='both', expand=True)\n",
    "        right_frame = tk.Frame(self.root, bg=bg)\n",
    "        right_frame.pack(side='right', fill='both', expand=True)\n",
    "\n",
    "        tk.Label(left_frame, text=\"\\U0001F3A7 Speech Emotion Recognition\", font=('Helvetica bold', 18), bg=bg, fg=fg).pack(pady=40)\n",
    "        tk.Button(left_frame, text=\"\\U0001F399 Record Audio\", command=self.record_audio_page, bg='orange').pack(pady=10)\n",
    "        tk.Button(left_frame, text=\"\\U0001F4C1 Upload Audio\", command=self.upload_audio_page, bg='lightgreen').pack(pady=10)\n",
    "        tk.Button(left_frame, text=\"\\U0001F4DC Prediction History\", command=self.show_history_page, bg='lightblue').pack(pady=10)\n",
    "        tk.Button(left_frame, text=\"\\u274C Exit\", command=self.confirm_exit, bg='red', fg='white').pack(pady=10)\n",
    "\n",
    "        if os.path.exists(self.logo_path):\n",
    "            logo_image = Image.open(self.logo_path).resize((400, 550), Image.Resampling.LANCZOS)\n",
    "            logo_tk = ImageTk.PhotoImage(logo_image)\n",
    "            tk.Label(right_frame, image=logo_tk, bg=bg).pack()\n",
    "            self.logo_img = logo_tk  # retain reference\n",
    "\n",
    "    def confirm_exit(self):\n",
    "        if messagebox.askokcancel(\"Exit\", \"Do you really want to exit?\"):\n",
    "            self.root.destroy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38fdc37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Speech Emotion Recognition\")\n",
    "        self.root.geometry(\"1000x600\")\n",
    "        self.dark_mode = False\n",
    "\n",
    "        self.base_emoji_path = r\"C:\\Users\\moham\\Downloads\\Emotion_Recognition_Project\\Speech_Emotion_Recognition\\Emotion Emojis\\Emoji\"\n",
    "        self.logo_path = r\"C:\\\\Users\\\\moham\\\\Downloads\\\\Emotion_Recognition_Project\\\\Speech_Emotion_Recognition\\\\images\\\\logo.png\"\n",
    "        self.emotion_to_emoji = {\n",
    "            \"HAPPY\": os.path.join(self.base_emoji_path, \"happy.gif\"),\n",
    "            \"SAD\": os.path.join(self.base_emoji_path, \"sad.gif\"),\n",
    "            \"ANGRY\": os.path.join(self.base_emoji_path, \"angry.gif\"),\n",
    "            \"SURPRISED\": os.path.join(self.base_emoji_path, \"surprised.gif\"),\n",
    "            \"NEUTRAL\": os.path.join(self.base_emoji_path, \"neutral.gif\"),\n",
    "            \"FEAR\": os.path.join(self.base_emoji_path, \"fear.gif\"),\n",
    "            \"DISGUST\": os.path.join(self.base_emoji_path, \"disgust.gif\")\n",
    "        }\n",
    "\n",
    "        self.emoji_label = None\n",
    "        self.emoji_image = None\n",
    "        self.prediction_history = []\n",
    "\n",
    "        self.create_menu()\n",
    "        self.show_home_page()\n",
    "\n",
    "    def clear_window(self):\n",
    "        for widget in self.root.winfo_children():\n",
    "            if not isinstance(widget, tk.Menu):\n",
    "                widget.destroy()\n",
    "\n",
    "    def apply_theme(self):\n",
    "        bg = '#1e1e1e' if self.dark_mode else 'white'\n",
    "        fg = 'white' if self.dark_mode else 'black'\n",
    "        self.root.configure(bg=bg)\n",
    "        return bg, fg\n",
    "\n",
    "    def back_button(self, command):\n",
    "        tk.Button(self.root, text=\"\\u2190 Back\", command=command, bg='lightgrey').place(x=10, y=10)\n",
    "\n",
    "    def create_menu(self):\n",
    "        self.menubar = tk.Menu(self.root)\n",
    "        app_menu = tk.Menu(self.menubar, tearoff=0)\n",
    "        app_menu.add_command(label=\"User Manual\", command=self.show_user_manual)\n",
    "        app_menu.add_command(label=\"Toggle Dark Mode\", command=self.toggle_dark_mode)\n",
    "        app_menu.add_command(label=\"About the App\", command=self.show_about_page)\n",
    "        self.menubar.add_cascade(label=\"Menu\", menu=app_menu)\n",
    "        self.root.config(menu=self.menubar)\n",
    "\n",
    "    def show_home_page(self):\n",
    "        self.clear_window()\n",
    "        bg, fg = self.apply_theme()\n",
    "\n",
    "        left_frame = tk.Frame(self.root, bg=bg)\n",
    "        left_frame.pack(side='left', fill='both', expand=True)\n",
    "        right_frame = tk.Frame(self.root, bg=bg)\n",
    "        right_frame.pack(side='right', fill='both', expand=True)\n",
    "\n",
    "        tk.Label(left_frame, text=\"\\U0001F3A7 Speech Emotion Recognition\", font=('Helvetica bold', 18), bg=bg, fg=fg).pack(pady=40)\n",
    "        tk.Button(left_frame, text=\"\\U0001F399 Record Audio\", command=self.record_audio_page, bg='orange').pack(pady=10)\n",
    "        tk.Button(left_frame, text=\"\\U0001F4C1 Upload Audio\", command=self.upload_audio_page, bg='lightgreen').pack(pady=10)\n",
    "        tk.Button(left_frame, text=\"\\U0001F4DC Prediction History\", command=self.show_history_page, bg='lightblue').pack(pady=10)\n",
    "        tk.Button(left_frame, text=\"\\u274C Exit\", command=self.confirm_exit, bg='red', fg='white').pack(pady=10)\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(self.logo_path):\n",
    "                logo_image = Image.open(self.logo_path)\n",
    "                logo_image = logo_image.resize((400, 550), Image.Resampling.LANCZOS)\n",
    "                self.logo_tk = ImageTk.PhotoImage(logo_image)\n",
    "                logo_label = tk.Label(right_frame, image=self.logo_tk, bg=bg)\n",
    "                logo_label.image = self.logo_tk\n",
    "                logo_label.pack()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading logo: {e}\")\n",
    "\n",
    "    def confirm_exit(self):\n",
    "        if messagebox.askokcancel(\"Exit\", \"Do you really want to exit?\"):\n",
    "            self.root.destroy()\n",
    "\n",
    "    def toggle_dark_mode(self):\n",
    "        self.dark_mode = not self.dark_mode\n",
    "        self.show_home_page()\n",
    "\n",
    "    def show_user_manual(self):\n",
    "        self.clear_window()\n",
    "        self.back_button(self.show_home_page)\n",
    "        bg, fg = self.apply_theme()\n",
    "        manual = (\n",
    "            \"ğŸ“˜ USER MANUAL\\n\\n\"\n",
    "            \"1. ğŸ™ Click 'Record Audio' to use your microphone.\\n\"\n",
    "            \"2. ğŸ“‚ Click 'Upload Audio' to select a .wav file.\\n\"\n",
    "            \"3. See predicted emotion, emoji and chart.\\n\"\n",
    "            \"4. Check 'Prediction History' for past results.\\n\"\n",
    "            \"5. Only '.wav' files are supported.\"\n",
    "        )\n",
    "        tk.Label(self.root, text=manual, justify=\"left\", font=('Arial', 12), wraplength=550, bg=bg, fg=fg).pack(padx=20, pady=30)\n",
    "\n",
    "    def show_about_page(self):\n",
    "        self.clear_window()\n",
    "        self.back_button(self.show_home_page)\n",
    "        bg, fg = self.apply_theme()\n",
    "        about = (\n",
    "            \"â„¹ï¸ ABOUT THE APP\\n\\n\"\n",
    "            \"ğŸ“Œ FEATURES:\\n\"\n",
    "            \"- Record/upload audio\\n- Predict emotion\\n- Emoji output\\n- Probability chart\\n- Export CSV\\n\\n\"\n",
    "            \"ğŸ“Œ APPLICATIONS:\\n\"\n",
    "            \"- AI Assistants\\n- Customer Service\\n- Mental Health\\n\\n\"\n",
    "            \"ğŸ“Œ CREDITS:\\n- Dataset: TESS\\n- Developed in Python\"\n",
    "        )\n",
    "        tk.Label(self.root, text=about, justify=\"left\", font=('Arial', 12), wraplength=550, bg=bg, fg=fg).pack(padx=20, pady=30)\n",
    "\n",
    "    def show_history_page(self):\n",
    "        self.clear_window()\n",
    "        self.back_button(self.show_home_page)\n",
    "        bg, fg = self.apply_theme()\n",
    "        tk.Label(self.root, text=\"ğŸ“– Prediction History\", font=('Helvetica bold', 16), bg=bg, fg=fg).pack(pady=20)\n",
    "        if self.prediction_history:\n",
    "            for i, (file_name, emotion) in enumerate(self.prediction_history[::-1], start=1):\n",
    "                tk.Label(self.root, text=f\"{i}. {file_name} â€” Emotion: {emotion}\", bg=bg, fg=fg).pack(anchor='w', padx=20)\n",
    "            tk.Button(self.root, text=\"ğŸ’¾ Export as CSV\", command=self.export_csv, bg='orange').pack(pady=10)\n",
    "        else:\n",
    "            tk.Label(self.root, text=\"No history yet.\", bg=bg, fg=fg).pack()\n",
    "\n",
    "    def export_csv(self):\n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "        if file_path:\n",
    "            with open(file_path, mode='w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"File Name\", \"Predicted Emotion\"])\n",
    "                writer.writerows(self.prediction_history)\n",
    "            messagebox.showinfo(\"Success\", \"History exported!\")\n",
    "\n",
    "    def upload_audio_page(self):\n",
    "        self.clear_window()\n",
    "        self.back_button(self.show_home_page)\n",
    "        bg, fg = self.apply_theme()\n",
    "        def choose_file():\n",
    "            file_path = filedialog.askopenfilename(filetypes=[(\"WAV Audio\", \"*.wav\")])\n",
    "            if file_path:\n",
    "                self.display_result(file_path, os.path.basename(file_path))\n",
    "        tk.Label(self.root, text=\"ğŸ“‚ Upload WAV File\", font=('Helvetica bold', 16), bg=bg, fg=fg).pack(pady=40)\n",
    "        tk.Button(self.root, text=\"Upload Audio\", command=choose_file, bg='orange').pack(pady=10)\n",
    "\n",
    "    def record_audio_page(self):\n",
    "        self.clear_window()\n",
    "        self.back_button(self.show_home_page)\n",
    "        bg, fg = self.apply_theme()\n",
    "        def record_and_predict():\n",
    "            duration = 4\n",
    "            fs = 44100\n",
    "            tk.Label(self.root, text=\"Recording...\", fg=\"red\", bg=bg).pack()\n",
    "            recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "            sd.wait()\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
    "                wav.write(temp_file.name, fs, recording)\n",
    "                self.display_result(temp_file.name, \"Recorded_Audio.wav\")\n",
    "        tk.Label(self.root, text=\"ğŸ™ Record Your Voice\", font=('Helvetica bold', 16), bg=bg, fg=fg).pack(pady=40)\n",
    "        tk.Button(self.root, text=\"Start Recording\", command=record_and_predict, bg='orange').pack(pady=10)\n",
    "\n",
    "    def display_result(self, file_path, file_name):\n",
    "        self.clear_window()\n",
    "        self.back_button(self.show_home_page)\n",
    "        bg, fg = self.apply_theme()\n",
    "        predicted_emotion, probabilities = predict_emotion(file_path)\n",
    "        self.prediction_history.append((file_name, predicted_emotion))\n",
    "        tk.Label(self.root, text=\"Predicted Emotion:\", font=('Helvetica bold', 16), bg=bg, fg=fg).pack(pady=10)\n",
    "        tk.Label(self.root, text=predicted_emotion, font=('Helvetica bold', 20), fg='blue', bg=bg).pack()\n",
    "\n",
    "        emoji_path = self.emotion_to_emoji.get(predicted_emotion.upper())\n",
    "        if emoji_path and os.path.exists(emoji_path):\n",
    "            self.emoji_image = tk.PhotoImage(file=emoji_path)\n",
    "            self.emoji_label = tk.Label(self.root, image=self.emoji_image, bg=bg)\n",
    "            self.emoji_label.image = self.emoji_image\n",
    "            self.emoji_label.pack(pady=10)\n",
    "\n",
    "        self.show_emotion_bar_chart(probabilities)\n",
    "\n",
    "    def show_emotion_bar_chart(self, probabilities):\n",
    "        fig, ax = plt.subplots(figsize=(6, 3), dpi=100)\n",
    "        emotions, probs = list(probabilities.keys()), list(probabilities.values())\n",
    "        ax.bar(emotions, probs, color='skyblue')\n",
    "        ax.set_title('Emotion Probabilities')\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_ylabel('Probability')\n",
    "        canvas = FigureCanvasTkAgg(fig, master=self.root)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2084a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Run the app\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = EmotionApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
